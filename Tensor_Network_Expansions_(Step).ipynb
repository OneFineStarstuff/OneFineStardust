{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP0yx1ZwEf85WlJHRED4cQ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/OneFineStardust/blob/main/Tensor_Network_Expansions_(Step).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorly"
      ],
      "metadata": {
        "id": "LoZDMdoxvGOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, Lx, Ly, d, D):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS tensor network.\n",
        "        Args:\n",
        "            Lx (int): Number of sites in the x-direction (rows).\n",
        "            Ly (int): Number of sites in the y-direction (columns).\n",
        "            d (int): Physical dimension of the local Hilbert space.\n",
        "            D (int): Bond dimension of the virtual indices.\n",
        "        \"\"\"\n",
        "        self.Lx = Lx\n",
        "        self.Ly = Ly\n",
        "        self.d = d\n",
        "        self.D = D\n",
        "\n",
        "        # Initialize tensors for each site in the 2D lattice\n",
        "        self.tensors = [[self.initialize_tensor(d, D) for _ in range(Ly)] for _ in range(Lx)]\n",
        "\n",
        "    def initialize_tensor(self, d, D):\n",
        "        \"\"\"\n",
        "        Initialize a random PEPS tensor with physical and virtual bonds.\n",
        "        \"\"\"\n",
        "        return np.random.randn(d, D, D, D, D)  # Physical, Left, Right, Up, Down\n",
        "\n",
        "    def contract_bond(self, tensor_a, tensor_b, axis_a, axis_b):\n",
        "        \"\"\"\n",
        "        Contract two tensors along specified axes.\n",
        "        Args:\n",
        "            tensor_a: First tensor.\n",
        "            tensor_b: Second tensor.\n",
        "            axis_a: Axis to contract in tensor_a.\n",
        "            axis_b: Axis to contract in tensor_b.\n",
        "        Returns:\n",
        "            Contracted tensor.\n",
        "        \"\"\"\n",
        "        # Debug tensor shapes\n",
        "        print(f\"Contracting tensors: {tensor_a.shape} with {tensor_b.shape}\")\n",
        "\n",
        "        # Ensure axis indices are positive and within bounds\n",
        "        axis_a = axis_a if axis_a >= 0 else tensor_a.ndim + axis_a\n",
        "        axis_b = axis_b if axis_b >= 0 else tensor_b.ndim + axis_b\n",
        "\n",
        "        # Validate shapes\n",
        "        if tensor_a.shape[axis_a] != tensor_b.shape[axis_b]:\n",
        "            raise ValueError(\n",
        "                f\"Bond dimensions do not match: {tensor_a.shape[axis_a]} != {tensor_b.shape[axis_b]}\"\n",
        "            )\n",
        "\n",
        "        # Perform contraction\n",
        "        return oe.contract(\n",
        "            tensor_a,\n",
        "            list(range(tensor_a.ndim)),\n",
        "            tensor_b,\n",
        "            list(range(tensor_b.ndim)),\n",
        "            optimize=\"optimal\"\n",
        "        )\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row to form a single tensor.\n",
        "        Args:\n",
        "            row_tensors: List of tensors in a row.\n",
        "        Returns:\n",
        "            Contracted row tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            # If the tensor is already a scalar, stop contracting\n",
        "            if contracted.ndim == 0:\n",
        "                break\n",
        "            contracted = self.contract_bond(contracted, t, axis_a=-1, axis_b=1)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS lattice.\n",
        "        Returns:\n",
        "            Scalar value of the fully contracted network.\n",
        "        \"\"\"\n",
        "        # Contract rows sequentially\n",
        "        row_contractions = [self.contract_row(row) for row in self.tensors]\n",
        "        result = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            # If the tensor is already a scalar, stop contracting\n",
        "            if result.ndim == 0:\n",
        "                break\n",
        "            result = self.contract_bond(result, row, axis_a=-1, axis_b=1)\n",
        "        return result\n",
        "\n",
        "# Example Usage\n",
        "Lx, Ly = 4, 4  # Lattice dimensions\n",
        "d, D = 2, 3    # Physical and bond dimensions\n",
        "\n",
        "peps = PEPS(Lx, Ly, d, D)\n",
        "result = peps.full_contraction()\n",
        "\n",
        "print(f\"Full contraction result: {result}\")"
      ],
      "metadata": {
        "id": "PV0gwHVTDEPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opt_einsum as oe\n",
        "import torch  # For parallelized GPU computations\n",
        "\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, Lx, Ly, d, D, use_gpu=False):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS tensor network.\n",
        "        Args:\n",
        "            Lx (int): Number of sites in the x-direction (rows).\n",
        "            Ly (int): Number of sites in the y-direction (columns).\n",
        "            d (int): Physical dimension of the local Hilbert space.\n",
        "            D (int): Bond dimension of the virtual indices.\n",
        "            use_gpu (bool): Enable GPU acceleration using PyTorch.\n",
        "        \"\"\"\n",
        "        self.Lx = Lx\n",
        "        self.Ly = Ly\n",
        "        self.d = d\n",
        "        self.D = D\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        # Initialize tensors for each site in the 2D lattice\n",
        "        self.tensors = [[self.initialize_tensor(d, D) for _ in range(Ly)] for _ in range(Lx)]\n",
        "\n",
        "    def initialize_tensor(self, d, D):\n",
        "        \"\"\"\n",
        "        Initialize a random PEPS tensor with physical and virtual bonds.\n",
        "        \"\"\"\n",
        "        tensor = np.random.randn(d, D, D, D, D)  # Physical, Left, Right, Up, Down\n",
        "        if self.use_gpu:\n",
        "            tensor = torch.tensor(tensor, dtype=torch.float32).to('cuda')\n",
        "        return tensor\n",
        "\n",
        "    def contract_bond(self, tensor_a, tensor_b, axis_a, axis_b):\n",
        "        \"\"\"\n",
        "        Contract two tensors along specified axes.\n",
        "        Args:\n",
        "            tensor_a: First tensor.\n",
        "            tensor_b: Second tensor.\n",
        "            axis_a: Axis to contract in tensor_a.\n",
        "            axis_b: Axis to contract in tensor_b.\n",
        "        Returns:\n",
        "            Contracted tensor.\n",
        "        \"\"\"\n",
        "        axis_a = axis_a if axis_a >= 0 else tensor_a.ndim + axis_a\n",
        "        axis_b = axis_b if axis_b >= 0 else tensor_b.ndim + axis_b\n",
        "        if tensor_a.shape[axis_a] != tensor_b.shape[axis_b]:\n",
        "            raise ValueError(\n",
        "                f\"Bond dimensions do not match: {tensor_a.shape[axis_a]} != {tensor_b.shape[axis_b]}\"\n",
        "            )\n",
        "        return oe.contract(\n",
        "            tensor_a,\n",
        "            list(range(tensor_a.ndim)),\n",
        "            tensor_b,\n",
        "            list(range(tensor_b.ndim)),\n",
        "            optimize=\"optimal\"\n",
        "        )\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row to form a single tensor.\n",
        "        Args:\n",
        "            row_tensors: List of tensors in a row.\n",
        "        Returns:\n",
        "            Contracted row tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            if contracted.ndim == 0:  # Stop if tensor is a scalar\n",
        "                break\n",
        "            contracted = self.contract_bond(contracted, t, axis_a=-1, axis_b=1)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS lattice.\n",
        "        Returns:\n",
        "            Scalar value of the fully contracted network.\n",
        "        \"\"\"\n",
        "        row_contractions = [self.contract_row(row) for row in self.tensors]\n",
        "        result = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            if result.ndim == 0:  # Stop if tensor is a scalar\n",
        "                break\n",
        "            result = self.contract_bond(result, row, axis_a=-1, axis_b=1)\n",
        "        return result\n",
        "\n",
        "    def apply_hamiltonian(self, h):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice.\n",
        "        Args:\n",
        "            h: Hamiltonian tensor (physical dimension x physical dimension).\n",
        "        \"\"\"\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        for i in range(self.Lx):\n",
        "            for j in range(self.Ly):\n",
        "                tensor = self.tensors[i][j]\n",
        "                self.tensors[i][j] = oe.contract(\"ab,bijkl->aijkl\", h, tensor)\n",
        "\n",
        "    def compute_observable(self, observable):\n",
        "        \"\"\"\n",
        "        Compute an observable using the PEPS framework.\n",
        "        Args:\n",
        "            observable: Observable tensor (physical dimension x physical dimension).\n",
        "        Returns:\n",
        "            Scalar value of the observable.\n",
        "        \"\"\"\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        result = 0.0\n",
        "        for row in self.tensors:\n",
        "            for tensor in row:\n",
        "                # Apply observable only on the physical index\n",
        "                physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "                result += physical_contracted.sum()\n",
        "        return result\n",
        "\n",
        "    def corner_transfer_matrix(self):\n",
        "        \"\"\"\n",
        "        Implement a simplified version of CTM for boundary approximations.\n",
        "        This is a placeholder for further development.\n",
        "        \"\"\"\n",
        "        print(\"CTM approximation placeholder - not yet implemented.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "Lx, Ly = 4, 4  # Lattice dimensions\n",
        "d, D = 2, 3    # Physical and bond dimensions\n",
        "\n",
        "# Enable GPU if available\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "peps = PEPS(Lx, Ly, d, D, use_gpu=use_gpu)\n",
        "\n",
        "# Example Hamiltonian\n",
        "hamiltonian = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    hamiltonian = torch.tensor(hamiltonian, dtype=torch.float32).to('cuda')\n",
        "\n",
        "peps.apply_hamiltonian(hamiltonian)\n",
        "\n",
        "# Compute an observable\n",
        "observable = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    observable = torch.tensor(observable, dtype=torch.float32).to('cuda')\n",
        "\n",
        "observable_result = peps.compute_observable(observable)\n",
        "print(f\"Observable result: {observable_result}\")\n",
        "\n",
        "# Perform full contraction\n",
        "result = peps.full_contraction()\n",
        "print(f\"Full contraction result: {result}\")"
      ],
      "metadata": {
        "id": "RYZX4RzmEe6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opt_einsum as oe\n",
        "import torch\n",
        "\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, Lx, Ly, d, D, use_gpu=False):\n",
        "        self.Lx = Lx\n",
        "        self.Ly = Ly\n",
        "        self.d = d\n",
        "        self.D = D\n",
        "        self.use_gpu = use_gpu\n",
        "        self.tensors = [[self.initialize_tensor(d, D) for _ in range(Ly)] for _ in range(Lx)]\n",
        "\n",
        "    def initialize_tensor(self, d, D):\n",
        "        tensor = np.random.randn(d, D, D, D, D)  # Physical, Left, Right, Up, Down\n",
        "        if self.use_gpu:\n",
        "            tensor = torch.tensor(tensor, dtype=torch.float32).to('cuda')\n",
        "        return tensor\n",
        "\n",
        "    def contract_bond(self, tensor_a, tensor_b, axis_a, axis_b):\n",
        "        axis_a = axis_a if axis_a >= 0 else tensor_a.ndim + axis_a\n",
        "        axis_b = axis_b if axis_b >= 0 else tensor_b.ndim + axis_b\n",
        "        if tensor_a.shape[axis_a] != tensor_b.shape[axis_b]:\n",
        "            raise ValueError(\n",
        "                f\"Bond dimensions do not match: {tensor_a.shape[axis_a]} != {tensor_b.shape[axis_b]}\"\n",
        "            )\n",
        "        return oe.contract(\n",
        "            tensor_a,\n",
        "            list(range(tensor_a.ndim)),\n",
        "            tensor_b,\n",
        "            list(range(tensor_b.ndim)),\n",
        "            optimize=\"optimal\"\n",
        "        )\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            if contracted.ndim == 0:\n",
        "                break\n",
        "            contracted = self.contract_bond(contracted, t, axis_a=-1, axis_b=1)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        row_contractions = [self.contract_row(row) for row in self.tensors]\n",
        "        result = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            if result.ndim == 0:\n",
        "                break\n",
        "            result = self.contract_bond(result, row, axis_a=-1, axis_b=1)\n",
        "        return result\n",
        "\n",
        "    def apply_hamiltonian(self, h):\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        for i in range(self.Lx):\n",
        "            for j in range(self.Ly):\n",
        "                tensor = self.tensors[i][j]\n",
        "                self.tensors[i][j] = oe.contract(\"ab,bijkl->aijkl\", h, tensor)\n",
        "\n",
        "    def compute_observable(self, observable):\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        result = 0.0\n",
        "        for row in self.tensors:\n",
        "            for tensor in row:\n",
        "                physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "                result += physical_contracted.sum()\n",
        "        return result\n",
        "\n",
        "    def compute_multi_site_observable(self, observable, sites):\n",
        "        print(f\"Computing multi-site observable on sites: {sites}\")\n",
        "        contracted_tensors = []\n",
        "        for (i, j) in sites:\n",
        "            tensor = self.tensors[i][j]\n",
        "            # Align physical dimension to observable if mismatched\n",
        "            if tensor.shape[0] != observable.shape[0]:\n",
        "                raise ValueError(f\"Physical dimension mismatch: {tensor.shape[0]} != {observable.shape[0]}\")\n",
        "            physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "            contracted_tensors.append(physical_contracted)\n",
        "\n",
        "        # Sequentially contract the tensors\n",
        "        result = contracted_tensors[0]\n",
        "        for t in contracted_tensors[1:]:\n",
        "            # Align virtual dimensions before contraction\n",
        "            if result.shape[-1] != t.shape[1]:\n",
        "                raise ValueError(f\"Bond mismatch during multi-site contraction: {result.shape[-1]} != {t.shape[1]}\")\n",
        "            result = self.contract_bond(result, t, axis_a=-1, axis_b=1)\n",
        "        return result.sum()\n",
        "\n",
        "    def corner_transfer_matrix(self, steps=2):\n",
        "        print(f\"Running CTM approximation for {steps} steps...\")\n",
        "        for step in range(steps):\n",
        "            for i in range(self.Lx):\n",
        "                for j in range(self.Ly):\n",
        "                    tensor = self.tensors[i][j]\n",
        "                    self.tensors[i][j] = tensor / tensor.norm() if self.use_gpu else tensor / np.linalg.norm(tensor)\n",
        "        print(\"CTM approximation completed.\")\n",
        "\n",
        "    def optimize_tensors(self):\n",
        "        print(\"Optimizing tensors using GPU... (placeholder)\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "Lx, Ly = 4, 4  # Lattice dimensions\n",
        "d, D = 2, 3    # Physical and bond dimensions\n",
        "\n",
        "# Enable GPU if available\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "peps = PEPS(Lx, Ly, d, D, use_gpu=use_gpu)\n",
        "\n",
        "# Example Hamiltonian\n",
        "hamiltonian = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    hamiltonian = torch.tensor(hamiltonian, dtype=torch.float32).to('cuda')\n",
        "\n",
        "peps.apply_hamiltonian(hamiltonian)\n",
        "\n",
        "# Compute an observable\n",
        "observable = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    observable = torch.tensor(observable, dtype=torch.float32).to('cuda')\n",
        "\n",
        "observable_result = peps.compute_observable(observable)\n",
        "print(f\"Observable result: {observable_result}\")\n",
        "\n",
        "# Compute a multi-site observable\n",
        "multi_site_observable = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    multi_site_observable = torch.tensor(multi_site_observable, dtype=torch.float32).to('cuda')\n",
        "\n",
        "# Ensure physical dimension alignment\n",
        "if multi_site_observable.shape[0] != d:\n",
        "    raise ValueError(\"Physical dimension of the observable does not match PEPS tensors.\")\n",
        "\n",
        "multi_site_result = peps.compute_multi_site_observable(multi_site_observable, [(0, 0), (1, 1)])\n",
        "print(f\"Multi-site observable result: {multi_site_result}\")\n",
        "\n",
        "# Perform full contraction\n",
        "result = peps.full_contraction()\n",
        "print(f\"Full contraction result: {result}\")\n",
        "\n",
        "# Perform boundary contraction via CTM\n",
        "peps.corner_transfer_matrix(steps=5)"
      ],
      "metadata": {
        "id": "HpVLeZ52E71u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opt_einsum as oe\n",
        "import torch\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, Lx, Ly, d, D, use_gpu=False):\n",
        "        self.Lx = Lx\n",
        "        self.Ly = Ly\n",
        "        self.d = d\n",
        "        self.D = D\n",
        "        self.use_gpu = use_gpu\n",
        "        self.tensors = [[self.initialize_tensor(d, D) for _ in range(Ly)] for _ in range(Lx)]\n",
        "\n",
        "    def initialize_tensor(self, d, D):\n",
        "        tensor = np.random.randn(d, D, D, D, D)  # Physical, Left, Right, Up, Down\n",
        "        if self.use_gpu:\n",
        "            tensor = torch.tensor(tensor, dtype=torch.float32).to('cuda')\n",
        "        return tensor\n",
        "\n",
        "    def contract_bond(self, tensor_a, tensor_b, axis_a, axis_b):\n",
        "        axis_a = axis_a if axis_a >= 0 else tensor_a.ndim + axis_a\n",
        "        axis_b = axis_b if axis_b >= 0 else tensor_b.ndim + axis_b\n",
        "        if tensor_a.shape[axis_a] != tensor_b.shape[axis_b]:\n",
        "            raise ValueError(\n",
        "                f\"Bond dimensions do not match: {tensor_a.shape[axis_a]} != {tensor_b.shape[axis_b]}\"\n",
        "            )\n",
        "        return oe.contract(\n",
        "            tensor_a,\n",
        "            list(range(tensor_a.ndim)),\n",
        "            tensor_b,\n",
        "            list(range(tensor_b.ndim)),\n",
        "            optimize=\"optimal\"\n",
        "        )\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            if contracted.ndim == 0:\n",
        "                break\n",
        "            contracted = self.contract_bond(contracted, t, axis_a=-1, axis_b=1)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        row_contractions = [self.contract_row(row) for row in self.tensors]\n",
        "        result = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            if result.ndim == 0:\n",
        "                break\n",
        "            result = self.contract_bond(result, row, axis_a=-1, axis_b=1)\n",
        "        return result\n",
        "\n",
        "    def apply_hamiltonian(self, h):\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        for i in range(self.Lx):\n",
        "            for j in range(self.Ly):\n",
        "                tensor = self.tensors[i][j]\n",
        "                self.tensors[i][j] = oe.contract(\"ab,bijkl->aijkl\", h, tensor)\n",
        "\n",
        "    def compute_observable(self, observable):\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        result = 0.0\n",
        "        for row in self.tensors:\n",
        "            for tensor in row:\n",
        "                physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "                result += physical_contracted.sum()\n",
        "        return result\n",
        "\n",
        "    def compute_multi_site_observable(self, observable, sites):\n",
        "        print(f\"Computing multi-site observable on sites: {sites}\")\n",
        "        contracted_tensors = []\n",
        "        for (i, j) in sites:\n",
        "            tensor = self.tensors[i][j]\n",
        "            if tensor.shape[0] != observable.shape[0]:\n",
        "                raise ValueError(f\"Physical dimension mismatch: {tensor.shape[0]} != {observable.shape[0]}\")\n",
        "            physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "            contracted_tensors.append(physical_contracted)\n",
        "\n",
        "        result = contracted_tensors[0]\n",
        "        for t in contracted_tensors[1:]:\n",
        "            if result.shape[-1] != t.shape[1]:\n",
        "                raise ValueError(f\"Bond mismatch during multi-site contraction: {result.shape[-1]} != {t.shape[1]}\")\n",
        "            result = self.contract_bond(result, t, axis_a=-1, axis_b=1)\n",
        "        return result.sum()\n",
        "\n",
        "    def corner_transfer_matrix(self, steps=2):\n",
        "        print(f\"Running CTM approximation for {steps} steps...\")\n",
        "        for step in range(steps):\n",
        "            for i in range(self.Lx):\n",
        "                for j in range(self.Ly):\n",
        "                    tensor = self.tensors[i][j]\n",
        "                    self.tensors[i][j] = tensor / tensor.norm() if self.use_gpu else tensor / np.linalg.norm(tensor)\n",
        "        print(\"CTM approximation completed.\")\n",
        "\n",
        "    def optimize_tensors(self):\n",
        "        print(\"Optimizing tensors using GPU... (placeholder)\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "Lx, Ly = 4, 4\n",
        "d, D = 2, 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "peps = PEPS(Lx, Ly, d, D, use_gpu=use_gpu)\n",
        "\n",
        "hamiltonian = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    hamiltonian = torch.tensor(hamiltonian, dtype=torch.float32).to('cuda')\n",
        "\n",
        "peps.apply_hamiltonian(hamiltonian)\n",
        "\n",
        "observable = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    observable = torch.tensor(observable, dtype=torch.float32).to('cuda')\n",
        "\n",
        "observable_result = peps.compute_observable(observable)\n",
        "print(f\"Observable result: {observable_result}\")\n",
        "\n",
        "multi_site_observable = np.random.randn(d, d)\n",
        "if use_gpu:\n",
        "    multi_site_observable = torch.tensor(multi_site_observable, dtype=torch.float32).to('cuda')\n",
        "\n",
        "if multi_site_observable.shape[0] != d:\n",
        "    raise ValueError(\"Physical dimension of the observable does not match PEPS tensors.\")\n",
        "\n",
        "multi_site_result = peps.compute_multi_site_observable(multi_site_observable, [(0, 0), (1, 1)])\n",
        "print(f\"Multi-site observable result: {multi_site_result}\")\n",
        "\n",
        "result = peps.full_contraction()\n",
        "print(f\"Full contraction result: {result}\")\n",
        "\n",
        "peps.corner_transfer_matrix(steps=5)"
      ],
      "metadata": {
        "id": "AGDMJBl13vGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rmxdtI1Rw7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dghR98iwV1c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKJmV1QmBvnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opt_einsum as oe\n",
        "import torch\n",
        "\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, Lx, Ly, d, D, use_gpu=False):\n",
        "        self.Lx = Lx  # Number of rows\n",
        "        self.Ly = Ly  # Number of columns\n",
        "        self.d = d    # Physical dimension\n",
        "        self.D = D    # Bond dimension\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        # Initialize tensors\n",
        "        self.tensors = [\n",
        "            [\n",
        "                self.initialize_tensor(d, D)\n",
        "                for _ in range(Ly)\n",
        "            ]\n",
        "            for _ in range(Lx)\n",
        "        ]\n",
        "\n",
        "    def initialize_tensor(self, d, D):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS tensor with shape (physical, left, right, up, down).\n",
        "        \"\"\"\n",
        "        tensor = np.random.randn(d, D, D, D, D)\n",
        "        if self.use_gpu:\n",
        "            tensor = torch.tensor(tensor, dtype=torch.float32).to('cuda')\n",
        "        else:\n",
        "            tensor = torch.tensor(tensor, dtype=torch.float32)\n",
        "        return tensor\n",
        "\n",
        "    def apply_hamiltonian(self, h):\n",
        "        \"\"\"\n",
        "        Apply a local Hamiltonian to each tensor.\n",
        "        \"\"\"\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        for i in range(self.Lx):\n",
        "            for j in range(self.Ly):\n",
        "                tensor = self.tensors[i][j]\n",
        "                self.tensors[i][j] = oe.contract(\"ab,bijkl->aijkl\", h, tensor)\n",
        "\n",
        "    def compute_observable(self, observable):\n",
        "        \"\"\"\n",
        "        Compute an observable over the entire PEPS.\n",
        "        \"\"\"\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        result = 0.0\n",
        "        for row in self.tensors:\n",
        "            for tensor in row:\n",
        "                physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "                result += physical_contracted.sum().item()\n",
        "        return result\n",
        "\n",
        "    def compute_multi_site_observable(self, observable, sites):\n",
        "        \"\"\"\n",
        "        Compute a multi-site observable over specified sites.\n",
        "        \"\"\"\n",
        "        print(f\"Computing multi-site observable on sites: {sites}\")\n",
        "        contracted_tensors = []\n",
        "        for (i, j) in sites:\n",
        "            tensor = self.tensors[i][j]\n",
        "            physical_contracted = oe.contract(\"ab,aijkl->bijkl\", observable, tensor)\n",
        "            contracted_tensors.append(physical_contracted)\n",
        "\n",
        "        result = contracted_tensors[0]\n",
        "        for idx, t in enumerate(contracted_tensors[1:]):\n",
        "            print(f\"Contracting tensor {idx+1}: result.shape={result.shape}, t.shape={t.shape}\")\n",
        "            result, t = self.ensure_bond_match(result, t)\n",
        "            result = oe.contract(\"...ij,...jk->...ik\", result, t)\n",
        "        return result.sum().item()\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS.\n",
        "        \"\"\"\n",
        "        print(\"Performing full contraction...\")\n",
        "        row_contractions = []\n",
        "        for row_idx, row in enumerate(self.tensors):\n",
        "            print(f\"Contracting row {row_idx}...\")\n",
        "            row_contracted = self.contract_row(row)\n",
        "            print(f\"Row {row_idx} contraction result: shape={row_contracted.shape}\")\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        result = row_contractions[0]\n",
        "        for i in range(1, len(row_contractions)):\n",
        "            print(\n",
        "                f\"Contracting rows: result.shape={result.shape}, \"\n",
        "                f\"row_contractions[{i}].shape={row_contractions[i].shape}\"\n",
        "            )\n",
        "            result, row_contractions[i] = self.ensure_bond_match(result, row_contractions[i])\n",
        "            result = oe.contract(\"...ij,...jk->...ik\", result, row_contractions[i])\n",
        "        return result.sum().item()\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract tensors in a single row along the horizontal bonds.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for idx, t in enumerate(row_tensors[1:]):\n",
        "            print(\n",
        "                f\"Contracting row tensors: contracted.shape={contracted.shape}, \"\n",
        "                f\"t[{idx+1}].shape={t.shape}\"\n",
        "            )\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contracted = oe.contract(\"...lm,...mn->...ln\", contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensures that bond dimensions of two tensors are aligned via zero-padding.\n",
        "        \"\"\"\n",
        "        def pad_tensor(t, target_shape):\n",
        "            \"\"\"\n",
        "            Zero-pad a tensor to the target shape.\n",
        "            \"\"\"\n",
        "            pad_sizes = [(0, max(0, target_dim - current_dim)) for current_dim, target_dim in zip(t.shape, target_shape)]\n",
        "            pad_sizes = [item for sublist in reversed(pad_sizes) for item in sublist]\n",
        "            return torch.nn.functional.pad(t, pad_sizes)\n",
        "\n",
        "        # Print tensor shapes for debugging\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "\n",
        "        # Pad all dimensions to the maximum shape\n",
        "        max_shape = tuple(max(s1, s2) for s1, s2 in zip(t1.shape, t2.shape))\n",
        "        t1_padded = pad_tensor(t1, max_shape)\n",
        "        t2_padded = pad_tensor(t2, max_shape)\n",
        "\n",
        "        print(f\"After padding: t1_padded.shape={t1_padded.shape}, t2_padded.shape={t2_padded.shape}\")\n",
        "        return t1_padded, t2_padded\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Lattice dimensions\n",
        "    Lx, Ly = 4, 4\n",
        "    # Physical and bond dimensions\n",
        "    d, D = 2, 3\n",
        "    # Check for GPU\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "\n",
        "    # Initialize PEPS\n",
        "    peps = PEPS(Lx, Ly, d, D, use_gpu=use_gpu)\n",
        "\n",
        "    # Initialize random Hamiltonian\n",
        "    hamiltonian = np.random.randn(d, d)\n",
        "    if use_gpu:\n",
        "        hamiltonian = torch.tensor(hamiltonian, dtype=torch.float32).to('cuda')\n",
        "    else:\n",
        "        hamiltonian = torch.tensor(hamiltonian, dtype=torch.float32)\n",
        "\n",
        "    # Apply Hamiltonian\n",
        "    peps.apply_hamiltonian(hamiltonian)\n",
        "\n",
        "    # Initialize random observable\n",
        "    observable = np.random.randn(d, d)\n",
        "    if use_gpu:\n",
        "        observable = torch.tensor(observable, dtype=torch.float32).to('cuda')\n",
        "    else:\n",
        "        observable = torch.tensor(observable, dtype=torch.float32)\n",
        "\n",
        "    # Compute single-site observable\n",
        "    observable_result = peps.compute_observable(observable)\n",
        "    print(f\"Observable result: {observable_result}\")\n",
        "\n",
        "    # Compute multi-site observable\n",
        "    multi_site_observable = np.random.randn(d, d)\n",
        "    if use_gpu:\n",
        "        multi_site_observable = torch.tensor(multi_site_observable, dtype=torch.float32).to('cuda')\n",
        "    else:\n",
        "        multi_site_observable = torch.tensor(multi_site_observable, dtype=torch.float32)\n",
        "\n",
        "    multi_site_result = peps.compute_multi_site_observable(multi_site_observable, [(0, 0), (1, 1)])\n",
        "    print(f\"Multi-site observable result: {multi_site_result}\")\n",
        "\n",
        "    # Perform full contraction\n",
        "    result = peps.full_contraction()\n",
        "    print(f\"Full contraction result: {result}\")"
      ],
      "metadata": {
        "id": "a9huE5y_HJXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9aMZ7JHfyKaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8BVcSLEyLRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls | grep torch"
      ],
      "metadata": {
        "id": "Uz8IhyqCtX8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch --upgrade"
      ],
      "metadata": {
        "id": "GQmJYSdNtcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "uyIurcYFulAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m venv clean_env\n",
        "!source clean_env/bin/activate  # Use clean_env\\Scripts\\activate on Windows\n",
        "!pip install torch opt_einsum"
      ],
      "metadata": {
        "id": "DGBSggEkumuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        h = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        return h\n",
        "\n",
        "    def compute_observable(self):\n",
        "        obs = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {obs.shape}\")\n",
        "        return obs\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensure that the bond dimensions between t1 and t2 match.\n",
        "        \"\"\"\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract a row of tensors into a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network.\n",
        "        \"\"\"\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)\n",
        "bond_dim = 3\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Perform full contraction\n",
        "full_contraction_result = peps.full_contraction()\n",
        "print(f\"Full contraction result: {full_contraction_result}\")"
      ],
      "metadata": {
        "id": "bQinNRx7u5VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        self.size = size  # PEPS lattice dimensions (rows, columns)\n",
        "        self.bond_dim = bond_dim  # Bond dimension of the PEPS\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Initialize the PEPS tensors with random values.\n",
        "        Each tensor is of shape [bond_dim, bond_dim, bond_dim, bond_dim].\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice. For simplicity, this is a random tensor.\n",
        "        \"\"\"\n",
        "        h = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        return h\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a random observable on the PEPS lattice for demonstration purposes.\n",
        "        \"\"\"\n",
        "        obs = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {obs.shape}\")\n",
        "        return obs\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensure that the bond dimensions between t1 and t2 match.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract a row of tensors into a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network.\n",
        "        \"\"\"\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Contract all rows together\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)  # PEPS lattice size (3x3 grid)\n",
        "bond_dim = 3  # Bond dimension\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Perform full contraction and reduce to scalar\n",
        "full_contraction_result = peps.full_contraction()\n",
        "final_result = full_contraction_result.sum()\n",
        "print(f\"Full contraction result (scalar): {final_result.item()}\")"
      ],
      "metadata": {
        "id": "t1U90RjevnGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS model with a given lattice size and bond dimension.\n",
        "\n",
        "        Parameters:\n",
        "        size: Tuple[int, int] - The PEPS lattice dimensions (rows, columns).\n",
        "        bond_dim: int - Bond dimension for the PEPS tensors.\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Randomly initialize the PEPS tensors for each lattice site.\n",
        "\n",
        "        Returns:\n",
        "        List[List[Tensor]]: A 2D grid of tensors, each of shape (bond_dim, bond_dim, bond_dim, bond_dim).\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice (dummy implementation with random tensor).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the Hamiltonian (random for demonstration).\n",
        "        \"\"\"\n",
        "        h = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        return h\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a dummy observable on the PEPS lattice (random tensor for demonstration).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the observable (random for demonstration).\n",
        "        \"\"\"\n",
        "        obs = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {obs.shape}\")\n",
        "        return obs\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Check that the bond dimensions of two tensors match for contraction.\n",
        "\n",
        "        Parameters:\n",
        "        t1, t2: Tensor - Tensors to be contracted.\n",
        "\n",
        "        Returns:\n",
        "        Tuple[Tensor, Tensor]: The original tensors after validation.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row of the lattice.\n",
        "\n",
        "        Parameters:\n",
        "        row_tensors: List[Tensor] - A list of tensors in a row.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The contracted row as a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network to compute the final value.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The fully contracted scalar result.\n",
        "        \"\"\"\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Contract all rows together\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted.sum()  # Reduce to scalar\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)  # PEPS lattice size (3x3 grid)\n",
        "bond_dim = 3  # Bond dimension\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Perform full contraction and print final result\n",
        "full_contraction_result = peps.full_contraction()\n",
        "print(f\"Full contraction result (scalar): {full_contraction_result.item()}\")"
      ],
      "metadata": {
        "id": "jVA8JZS9wO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS model with a given lattice size and bond dimension.\n",
        "\n",
        "        Parameters:\n",
        "        size: Tuple[int, int] - The PEPS lattice dimensions (rows, columns).\n",
        "        bond_dim: int - Bond dimension for the PEPS tensors.\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Randomly initialize the PEPS tensors for each lattice site.\n",
        "\n",
        "        Returns:\n",
        "        List[List[Tensor]]: A 2D grid of tensors, each of shape (bond_dim, bond_dim, bond_dim, bond_dim).\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice (dummy implementation with random tensor).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the Hamiltonian (random for demonstration).\n",
        "        \"\"\"\n",
        "        h = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        return h\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a dummy observable on the PEPS lattice (random tensor for demonstration).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the observable (random for demonstration).\n",
        "        \"\"\"\n",
        "        obs = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {obs.shape}\")\n",
        "        return obs\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Check that the bond dimensions of two tensors match for contraction.\n",
        "\n",
        "        Parameters:\n",
        "        t1, t2: Tensor - Tensors to be contracted.\n",
        "\n",
        "        Returns:\n",
        "        Tuple[Tensor, Tensor]: The original tensors after validation.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row of the lattice.\n",
        "\n",
        "        Parameters:\n",
        "        row_tensors: List[Tensor] - A list of tensors in a row.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The contracted row as a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network to compute the final value.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The fully contracted scalar result.\n",
        "        \"\"\"\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Contract all rows together\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted.sum()  # Reduce to scalar\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)  # PEPS lattice size (3x3 grid)\n",
        "bond_dim = 3  # Bond dimension\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Perform full contraction and print final result\n",
        "full_contraction_result = peps.full_contraction()\n",
        "print(f\"Full contraction result (scalar): {full_contraction_result.item()}\")"
      ],
      "metadata": {
        "id": "rydFovZNw2vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS model with a given lattice size and bond dimension.\n",
        "\n",
        "        Parameters:\n",
        "        size: Tuple[int, int] - The PEPS lattice dimensions (rows, columns).\n",
        "        bond_dim: int - Bond dimension for the PEPS tensors.\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Randomly initialize the PEPS tensors for each lattice site.\n",
        "\n",
        "        Returns:\n",
        "        List[List[Tensor]]: A 2D grid of tensors, each of shape (bond_dim, bond_dim, bond_dim, bond_dim).\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice (dummy implementation with random tensor).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the Hamiltonian (random for demonstration).\n",
        "        \"\"\"\n",
        "        h = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {h.shape}\")\n",
        "        return h\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a dummy observable on the PEPS lattice (random tensor for demonstration).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the observable (random for demonstration).\n",
        "        \"\"\"\n",
        "        obs = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {obs.shape}\")\n",
        "        return obs\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensure that the bond dimensions of two tensors match for contraction.\n",
        "\n",
        "        Parameters:\n",
        "        t1, t2: Tensor - Tensors to be contracted.\n",
        "\n",
        "        Returns:\n",
        "        Tuple[Tensor, Tensor]: The original tensors after validation.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row of the lattice.\n",
        "\n",
        "        Parameters:\n",
        "        row_tensors: List[Tensor] - A list of tensors in a row.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The contracted row as a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network to compute the final value.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The fully contracted scalar result.\n",
        "        \"\"\"\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Contract all rows together\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted.sum()  # Reduce to scalar\n",
        "\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)  # PEPS lattice size (3x3 grid)\n",
        "bond_dim = 3  # Bond dimension\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Perform full contraction and print final result\n",
        "full_contraction_result = peps.full_contraction()\n",
        "print(f\"Full contraction result (scalar): {full_contraction_result.item()}\")"
      ],
      "metadata": {
        "id": "Zf4URV3Nxe7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS model with a given lattice size and bond dimension.\n",
        "\n",
        "        Parameters:\n",
        "        size: Tuple[int, int] - The PEPS lattice dimensions (rows, columns).\n",
        "        bond_dim: int - Bond dimension for the PEPS tensors.\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Randomly initialize the PEPS tensors for each lattice site.\n",
        "\n",
        "        Returns:\n",
        "        List[List[Tensor]]: A 2D grid of tensors, each of shape (bond_dim, bond_dim, bond_dim, bond_dim).\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                # Initialize 4D tensors for each PEPS site\n",
        "                tensor_shape = [self.bond_dim] * 4\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a Hamiltonian to the PEPS lattice (random tensor for demonstration).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the Hamiltonian.\n",
        "        \"\"\"\n",
        "        hamiltonian = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {hamiltonian.shape}\")\n",
        "        return hamiltonian\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a dummy observable on the PEPS lattice.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the observable (random for demonstration).\n",
        "        \"\"\"\n",
        "        observable = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        return observable\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensure that the bond dimensions of two tensors match for contraction.\n",
        "\n",
        "        Parameters:\n",
        "        t1, t2: Tensor - Tensors to be contracted.\n",
        "\n",
        "        Returns:\n",
        "        Tuple[Tensor, Tensor]: The original tensors after validation.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row of the lattice.\n",
        "\n",
        "        Parameters:\n",
        "        row_tensors: List[Tensor] - A list of tensors in a row.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The contracted row as a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def full_contraction(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS tensor network to compute the final value.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The fully contracted scalar result.\n",
        "        \"\"\"\n",
        "        # Step 1: Contract each row into a single tensor\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Step 2: Contract all rows together into a single scalar\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted.sum()  # Reduce to scalar\n",
        "\n",
        "\n",
        "# Define the PEPS model\n",
        "size = (3, 3)  # PEPS lattice size (3x3 grid)\n",
        "bond_dim = 3  # Bond dimension\n",
        "peps = PEPS(size, bond_dim)\n",
        "\n",
        "# Step 1: Apply Hamiltonian\n",
        "hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "# Step 2: Compute observable\n",
        "observable = peps.compute_observable()\n",
        "\n",
        "# Print observable result\n",
        "observable_result = observable.sum()\n",
        "print(f\"Observable result: {observable_result.item()}\")\n",
        "\n",
        "# Step 3: Perform full contraction and print final result\n",
        "full_contraction_result = peps.full_contraction()\n",
        "print(f\"Full contraction result (scalar): {full_contraction_result.item()}\")"
      ],
      "metadata": {
        "id": "JgdAo7jGyHFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        \"\"\"\n",
        "        Initialize a PEPS model with a given lattice size and bond dimension.\n",
        "\n",
        "        Parameters:\n",
        "        size: Tuple[int, int] - The PEPS lattice dimensions (rows, columns).\n",
        "        bond_dim: int - Bond dimension for the PEPS tensors.\n",
        "        \"\"\"\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = self.initialize_tensors()\n",
        "\n",
        "    def initialize_tensors(self):\n",
        "        \"\"\"\n",
        "        Randomly initialize the PEPS tensors for each lattice site.\n",
        "\n",
        "        Returns:\n",
        "        List[List[Tensor]]: A 2D grid of tensors, each of shape (bond_dim, bond_dim, bond_dim, bond_dim).\n",
        "        \"\"\"\n",
        "        tensors = []\n",
        "        for i in range(self.size[0]):\n",
        "            row = []\n",
        "            for j in range(self.size[1]):\n",
        "                tensor_shape = [self.bond_dim] * 4  # Bond dimensions: left, right, up, down\n",
        "                row.append(torch.rand(*tensor_shape, requires_grad=True))\n",
        "            tensors.append(row)\n",
        "        return tensors\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"\n",
        "        Apply a random Hamiltonian to the PEPS lattice (for demonstration).\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the Hamiltonian.\n",
        "        \"\"\"\n",
        "        hamiltonian = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Applying Hamiltonian: {hamiltonian.shape}\")\n",
        "        return hamiltonian\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"\n",
        "        Compute a dummy observable on the PEPS lattice.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: A tensor representing the observable (random for demonstration).\n",
        "        \"\"\"\n",
        "        observable = torch.rand(self.size, requires_grad=True)\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        return observable\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"\n",
        "        Ensure that the bond dimensions of two tensors match for contraction.\n",
        "\n",
        "        Parameters:\n",
        "        t1, t2: Tensor - Tensors to be contracted.\n",
        "\n",
        "        Returns:\n",
        "        Tuple[Tensor, Tensor]: The original tensors after validation.\n",
        "        \"\"\"\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        if t1.shape[-1] != t2.shape[0]:\n",
        "            raise ValueError(\"Bond dimensions mismatch. Tensor contraction invalid.\")\n",
        "        return t1, t2\n",
        "\n",
        "    def contract_row(self, row_tensors):\n",
        "        \"\"\"\n",
        "        Contract all tensors in a single row of the lattice.\n",
        "\n",
        "        Parameters:\n",
        "        row_tensors: List[Tensor] - A list of tensors in a row.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The contracted row as a single tensor.\n",
        "        \"\"\"\n",
        "        contracted = row_tensors[0]\n",
        "        for t in row_tensors[1:]:\n",
        "            contracted, t = self.ensure_bond_match(contracted, t)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, t)\n",
        "        return contracted\n",
        "\n",
        "    def contract_full_lattice(self):\n",
        "        \"\"\"\n",
        "        Perform a full contraction of the PEPS lattice, reducing it to a scalar.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: The final scalar result after full contraction.\n",
        "        \"\"\"\n",
        "        # Step 1: Contract each row\n",
        "        row_contractions = []\n",
        "        for row in self.tensors:\n",
        "            row_contracted = self.contract_row(row)\n",
        "            row_contractions.append(row_contracted)\n",
        "\n",
        "        # Step 2: Contract all rows\n",
        "        contracted = row_contractions[0]\n",
        "        for row in row_contractions[1:]:\n",
        "            contracted, row = self.ensure_bond_match(contracted, row)\n",
        "            contraction_string = \"abcd,bcde->acde\"\n",
        "            contracted = oe.contract(contraction_string, contracted, row)\n",
        "\n",
        "        return contracted.sum()  # Reduce to scalar\n",
        "\n",
        "    def compute(self):\n",
        "        \"\"\"\n",
        "        Execute the full PEPS computation: Hamiltonian, observable, and full contraction.\n",
        "        \"\"\"\n",
        "        # Step 1: Apply Hamiltonian\n",
        "        hamiltonian = self.apply_hamiltonian()\n",
        "\n",
        "        # Step 2: Compute observable\n",
        "        observable = self.compute_observable()\n",
        "        observable_result = observable.sum().item()\n",
        "        print(f\"Observable result: {observable_result}\")\n",
        "\n",
        "        # Step 3: Perform full contraction\n",
        "        full_contraction_result = self.contract_full_lattice().item()\n",
        "        print(f\"Full contraction result (scalar): {full_contraction_result}\")\n",
        "\n",
        "\n",
        "# Define PEPS parameters\n",
        "size = (3, 3)  # Lattice size\n",
        "bond_dim = 3  # Bond dimension\n",
        "\n",
        "# Initialize and compute with PEPS\n",
        "peps = PEPS(size, bond_dim)\n",
        "peps.compute()"
      ],
      "metadata": {
        "id": "0hBiEHe6yys4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeaI_7SZzSF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7GbA3B8VH2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9TO3trqVIqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = [[torch.rand(bond_dim, bond_dim, bond_dim, bond_dim, requires_grad=True)\n",
        "                         for _ in range(size[1])] for _ in range(size[0])]\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"Apply a simple Hamiltonian (as a placeholder).\"\"\"\n",
        "        hamiltonian = torch.rand(self.size)\n",
        "        print(f\"Applying Hamiltonian: {hamiltonian.shape}\")\n",
        "        return hamiltonian\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"Compute a simple observable (as a placeholder).\"\"\"\n",
        "        observable = torch.rand(self.size)\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        return observable.sum()\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"Ensure tensors have matching bonds for contraction.\"\"\"\n",
        "        if t1.shape != t2.shape:\n",
        "            raise ValueError(f\"Bond mismatch: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "\n",
        "    def contract_two_tensors(self, t1, t2):\n",
        "        \"\"\"Contract two tensors.\"\"\"\n",
        "        self.ensure_bond_match(t1, t2)\n",
        "        return torch.tensordot(t1, t2, dims=([3, 2], [1, 0]))  # Adjust the contraction indices\n",
        "\n",
        "    def contract_row(self, row):\n",
        "        \"\"\"Contract a row of tensors.\"\"\"\n",
        "        result = row[0]\n",
        "        for tensor in row[1:]:\n",
        "            result = self.contract_two_tensors(result, tensor)\n",
        "        return result\n",
        "\n",
        "    def contract_full_lattice(self):\n",
        "        \"\"\"Contract the entire PEPS lattice.\"\"\"\n",
        "        contracted_rows = [self.contract_row(row) for row in self.tensors]\n",
        "        result = contracted_rows[0]\n",
        "        for row in contracted_rows[1:]:\n",
        "            result = self.contract_two_tensors(result, row)\n",
        "        print(f\"Full contraction result (scalar): {result.sum().item()}\")\n",
        "        return result.sum()\n",
        "\n",
        "def optimize_peps(peps, lr=1e-2, steps=100):\n",
        "    \"\"\"Optimize PEPS tensors to minimize energy.\"\"\"\n",
        "    optimizer = torch.optim.Adam([tensor for row in peps.tensors for tensor in row], lr=lr)\n",
        "    for step in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        energy = peps.contract_full_lattice()  # Use full contraction as energy\n",
        "        loss = energy\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}, Energy: {loss.item():.4f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    size = (3, 3)  # PEPS grid size\n",
        "    bond_dim = 3   # Bond dimension\n",
        "    peps = PEPS(size, bond_dim)\n",
        "\n",
        "    # Step 1: Apply Hamiltonian\n",
        "    hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "    # Step 2: Compute observable\n",
        "    observable = peps.compute_observable()\n",
        "    print(f\"Observable result: {observable}\")\n",
        "\n",
        "    # Step 3: Optimize PEPS tensors\n",
        "    print(\"Starting optimization...\")\n",
        "    optimize_peps(peps, lr=1e-2, steps=50)"
      ],
      "metadata": {
        "id": "rFjJVe-czufy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim):\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.tensors = [[torch.rand(bond_dim, bond_dim, bond_dim, bond_dim, requires_grad=True)\n",
        "                         for _ in range(size[1])] for _ in range(size[0])]\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        \"\"\"Apply a simple Hamiltonian (as a placeholder).\"\"\"\n",
        "        hamiltonian = torch.rand(self.size)\n",
        "        print(f\"Applying Hamiltonian: {hamiltonian.shape}\")\n",
        "        return hamiltonian\n",
        "\n",
        "    def compute_observable(self):\n",
        "        \"\"\"Compute a simple observable (as a placeholder).\"\"\"\n",
        "        observable = torch.rand(self.size)\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        return observable.sum()\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        \"\"\"Ensure tensors have matching bonds for contraction.\"\"\"\n",
        "        if t1.shape != t2.shape:\n",
        "            raise ValueError(f\"Bond mismatch: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "\n",
        "    def contract_two_tensors(self, t1, t2):\n",
        "        \"\"\"Contract two tensors.\"\"\"\n",
        "        self.ensure_bond_match(t1, t2)\n",
        "        return torch.tensordot(t1, t2, dims=([3, 2], [1, 0]))  # Adjust the contraction indices\n",
        "\n",
        "    def contract_row(self, row):\n",
        "        \"\"\"Contract a row of tensors.\"\"\"\n",
        "        result = row[0]\n",
        "        for tensor in row[1:]:\n",
        "            result = self.contract_two_tensors(result, tensor)\n",
        "        return result\n",
        "\n",
        "    def contract_full_lattice(self):\n",
        "        \"\"\"Contract the entire PEPS lattice.\"\"\"\n",
        "        contracted_rows = [self.contract_row(row) for row in self.tensors]\n",
        "        result = contracted_rows[0]\n",
        "        for row in contracted_rows[1:]:\n",
        "            result = self.contract_two_tensors(result, row)\n",
        "        print(f\"Full contraction result (scalar): {result.sum().item()}\")\n",
        "        return result.sum()\n",
        "\n",
        "def optimize_peps(peps, lr=1e-2, steps=100):\n",
        "    \"\"\"Optimize PEPS tensors to minimize energy.\"\"\"\n",
        "    optimizer = torch.optim.Adam([tensor for row in peps.tensors for tensor in row], lr=lr)\n",
        "    for step in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        energy = peps.contract_full_lattice()  # Use full contraction as energy\n",
        "        loss = energy\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}, Energy: {loss.item():.4f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    size = (3, 3)  # PEPS grid size\n",
        "    bond_dim = 3   # Bond dimension\n",
        "    peps = PEPS(size, bond_dim)\n",
        "\n",
        "    # Step 1: Apply Hamiltonian\n",
        "    hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "    # Step 2: Compute observable\n",
        "    observable = peps.compute_observable()\n",
        "    print(f\"Observable result: {observable}\")\n",
        "\n",
        "    # Step 3: Optimize PEPS tensors\n",
        "    print(\"Starting optimization...\")\n",
        "    optimize_peps(peps, lr=1e-2, steps=50)"
      ],
      "metadata": {
        "id": "GIKK6V4rDr-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import opt_einsum as oe\n",
        "\n",
        "class PEPS:\n",
        "    def __init__(self, size, bond_dim, device='cuda'):\n",
        "        self.size = size\n",
        "        self.bond_dim = bond_dim\n",
        "        self.device = device\n",
        "        self.tensors = [[torch.rand(bond_dim, bond_dim, bond_dim, bond_dim, requires_grad=True, device=device)\n",
        "                         for _ in range(size[1])] for _ in range(size[0])]\n",
        "\n",
        "    def apply_hamiltonian(self):\n",
        "        hamiltonian = torch.rand(self.size, device=self.device)\n",
        "        print(f\"Applying Hamiltonian: {hamiltonian.shape}\")\n",
        "        return hamiltonian\n",
        "\n",
        "    def compute_observable(self):\n",
        "        observable = torch.rand(self.size, device=self.device)\n",
        "        print(f\"Computing observable: {observable.shape}\")\n",
        "        return observable.sum()\n",
        "\n",
        "    def ensure_bond_match(self, t1, t2):\n",
        "        if t1.shape != t2.shape:\n",
        "            raise ValueError(f\"Bond mismatch: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "        print(f\"Ensuring bond match: t1.shape={t1.shape}, t2.shape={t2.shape}\")\n",
        "\n",
        "    def contract_two_tensors(self, t1, t2):\n",
        "        self.ensure_bond_match(t1, t2)\n",
        "        return torch.tensordot(t1, t2, dims=([3, 2], [1, 0]))\n",
        "\n",
        "    def contract_row(self, row):\n",
        "        result = row[0]\n",
        "        for tensor in row[1:]:\n",
        "            result = self.contract_two_tensors(result, tensor)\n",
        "        return result\n",
        "\n",
        "    def contract_full_lattice(self):\n",
        "        contracted_rows = [self.contract_row(row) for row in self.tensors]\n",
        "        result = contracted_rows[0]\n",
        "        for row in contracted_rows[1:]:\n",
        "            result = self.contract_two_tensors(result, row)\n",
        "        print(f\"Full contraction result (scalar): {result.sum().item()}\")\n",
        "        return result.sum()\n",
        "\n",
        "    # Extend observable computation to include multi-site observables\n",
        "    def compute_multi_site_observable(self):\n",
        "        observables = []\n",
        "        for i in range(self.size[0] - 1):\n",
        "            for j in range(self.size[1] - 1):\n",
        "                observable = torch.tensordot(self.tensors[i][j], self.tensors[i + 1][j + 1], dims=([2, 3], [0, 1]))\n",
        "                observables.append(observable)\n",
        "        total_observable = sum(observables)\n",
        "        print(f\"Multi-site observable: {total_observable.item()}\")\n",
        "        return total_observable\n",
        "\n",
        "def optimize_peps(peps, lr=1e-2, steps=100):\n",
        "    optimizer = torch.optim.Adam([tensor for row in peps.tensors for tensor in row], lr=lr)\n",
        "    for step in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        energy = peps.contract_full_lattice()\n",
        "        loss = energy\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step}, Energy: {loss.item():.4f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    size = (3, 3)\n",
        "    bond_dim = 3\n",
        "    peps = PEPS(size, bond_dim)\n",
        "\n",
        "    # Step 1: Apply Hamiltonian\n",
        "    hamiltonian = peps.apply_hamiltonian()\n",
        "\n",
        "    # Step 2: Compute observable\n",
        "    observable = peps.compute_observable()\n",
        "    print(f\"Observable result: {observable}\")\n",
        "\n",
        "    # Step 3: Compute multi-site observable\n",
        "    multi_site_observable = peps.compute_multi_site_observable()\n",
        "    print(f\"Multi-site observable result: {multi_site_observable}\")\n",
        "\n",
        "    # Step 4: Optimize PEPS tensors\n",
        "    print(\"Starting optimization...\")\n",
        "    optimize_peps(peps, lr=1e-2, steps=50)"
      ],
      "metadata": {
        "id": "IzmpK2ij_91v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}